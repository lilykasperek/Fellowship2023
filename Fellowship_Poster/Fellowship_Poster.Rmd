---
title: Visualizing Student Evaluation Data
title_textsize: "82pt"
titletext_fontfamily: Georgia, serif;
font_family: Georgia, serif;
author:
  - name: Lily Kasperek
author_textsize: "57pt"
affiliation:
  - address: Department of Math, Computer Science, and Statistics at St. Lawrence University
  - address: Advised by Dr. Matt Higham
column_numbers: 3
output: 
  posterdown::posterdown_html:
    self_contained: false
poster_height: "36in"
poster_width: "48in"
primary_colour: "#440154"
accent_colour: "#39568CFF"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, singlespacing = TRUE)
```

# Goal and Description

-   Create Shiny App to scrape student evaluation data from PDFs and provide a more in-depth analysis of the data by providing appropriate visuals

    -   <font size="6">*Note:* Ordinal student evaluations are often biased, with research finding biases against women and people of color (Chavez and Mitchell). This project is intended to serve as a tool to view one's own strengths and weaknesses, not as a means for comparison. Keeping this in mind, university averages are not used in this project.</font>

-   Model and predict ordinal responses based on student class year and sex

**Process**

1.  Scrape data from summary reports

2.  Wrangle data and construct visualizations

3.  Write functions for data scraping and wrangling

4.  Build and test Shiny App

# Likert Scale Data

-   SLU student evaluations use a 7-point Likert scale, which refers to the set of potential responses to different statements ranging from *Strongly Disagree* to *Strongly Agree*

    -   Example statement: *The instructor was an effective teacher*

-   Likert scale data is best analyzed and interpreted through visualizations rather than mean score of responses

```{r, out.width = "925px", fig.align = "center"}
library(tidyverse)
year_label <- as_labeller(c
                ('1' = "Year 1",
                '2' = "Year 2"))
toy_df <- tibble(year = c(rep(1, 7), rep(2, 7)),
                 resp = rep(c("Strongly Agree", "Agree", "Agree somewhat", "Neutral",
                              "Disagree somewhat", "Disagree", "Strongly Disagree"), 2),
                 n_resp = c(0, 13, 1, 0, 1, 13, 0,
                            1, 2, 3, 16, 3, 2, 1)) |>
  mutate(resp = fct_inorder(resp))
ggplot(data = toy_df, aes(x = resp, y = n_resp)) +
  geom_col(colour = "black", fill = "#440154") +
  facet_wrap(~year,
             labeller = year_label) +
  coord_flip() +
  labs(x = "Response", y = "Number of Students",
       title = "Example Distribution using Likert Scale Data") +
  theme_classic(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5)) 
```

-   The mean of both data sets is the same (4 points, or Neutral) but the distributions are very different

-   Using averages fails to communicate what was actually reported by participants, illustrating the danger of using the averages of Likert Scale data

# Shiny App

```{r, results = 'hide', message = FALSE, warning = FALSE}
library(tidyverse)
library(pdftools)
library(shiny)
library(shinythemes)
library(shadowtext)
library(data.table)
library(viridis)
library(bslib)
library(dplyr)
library(here)
source(here("pdf_function_full.R"))
source(here("meta_function.R"))
source(here("multiple_pdf_function.R"))
intro_stat_df <- pdf_function_full(here("STAT113_Fall_2020_1_edited.pdf"))
intro_stat <- intro_stat_df |>
  filter(full_question != "Q4a. Workload" &
           full_question != "Q4b. Grading" &
           full_question != "Q4c. Sophistication")
intro_stat

labels <- meta_function(here("STAT113_Fall_2020_1_edited.pdf"))
labels
labels[1, 1]
labels[1, 2]
labels[1, 3]
labels[1, 4]
title <- paste(labels[1, 2], labels[1, 1], sep = " ", collapse = NULL)
title
subtitle <- paste(labels[1, 3], labels[1, 4], sep = " ", collapse = NULL)
subtitle
```

```{r, out.width = "1025px", fig.align = "center"}
ggplot(data = intro_stat, aes(x = responses_hm, y = fct_rev(full_question),
                              fill = count_hm)) +
  geom_tile() +
  scale_fill_viridis_c(option = "viridis",
                         direction = 1) +
  labs(x = "Responses",
       y = "Questions",
       fill = "Count",
       title = title,
       subtitle = subtitle) +
  theme_classic(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5,
                                  size = 11),
        plot.subtitle = element_text(hjust = 0.5,
                                     size = 10),
        legend.box.background = element_rect(colour = "black"),
        axis.text.x = element_text(size = 6)) 
```

-   <font size="6">*Possible interpretation:* Stronger in organization and timeliness, weaker in communicating course relevance</font>

```{r, results = 'hide', message = FALSE, warning = FALSE}
intro_stat2 <- intro_stat_df |>
  filter(full_question == "Q4a. Workload" |
           full_question == "Q4b. Grading" |
           full_question == "Q4c. Sophistication")
intro_stat2 <- intro_stat2 |>
  mutate(responses_hm = fct_relevel(responses_hm, c("Too Low",
                                                    "Somewhat Low",
                                                    "Appropriate",
                                                    "Somewhat High",
                                                    "Too High")))
```

```{r, out.width = "925px", fig.align = "center"}
ggplot(data = intro_stat2, aes(x = responses_hm, y = fct_rev(full_question),
                              fill = count_hm)) +
  geom_tile() +
  scale_fill_viridis_c(option = "viridis",
                         direction = 1) +
  labs(x = "Responses",
       y = "Questions",
       fill = "Count",
       title = title,
       subtitle = subtitle) +
  theme_classic(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5,
                                  size = 11),
        plot.subtitle = element_text(hjust = 0.5,
                                     size = 10),
        legend.box.background = element_rect(colour = "black"),
        axis.text.x = element_text(size = 7)) 
```

-   <font size="6">*Possible interpretation:* Stronger in grading, weaker in workload and sophistication</font>

```{r,  results = 'hide', message = FALSE, warning = FALSE}
intro_stat_mult <- multiple_pdf_function(here("STAT113_Fall_2020_1_edited.pdf"))
stat_mult <- intro_stat_mult |>
  filter(full_question == "Q6c. Effective")
stat_mult
intro_data_df <- multiple_pdf_function(here("STAT234_Fall_2022_edited.pdf"))
intro_data <- intro_data_df |>
  filter(full_question == "Q6c. Effective")
intro_data
full_df <- bind_rows(stat_mult, intro_data)
```

```{r, out.width = "1025px", fig.align = "center"}
ggplot(data = full_df, aes(x = count_hm, y = responses_hm,
                           fill = responses_hm)) +
  geom_col() +
  scale_fill_viridis_d() +
  facet_wrap(~Semester + course, ncol = 1) +
  theme_classic(base_size = 14) +
  labs(x = "Count",
       y = "Responses",
       title = "Comparing SUBJ 10001 to SUBJ 20001",
       subtitle = "Q6c. Effective") +
  theme(legend.position = "none",
        plot.title = element_text(hjust = 0.5,
                                  size = 10),
        plot.subtitle = element_text(hjust = 0.5,
                                     size = 9))
```

-   <font size="6">*Note:* Usually used to compare same course across time</font>
-   <font size="6">*Possible interpretation:* Stronger in Fall of 2022 as an effective instructor (could be related to course level)</font>

# Additional Visualization

-   Static visualization of new question added to student evaluations

```{r, out.width = "850px", results = 'hide', fig.align = "center"}
toy_df_full <- tibble::tibble(student_id = c(LETTERS[1:15]),
               "a. Course materials" = c(0, rep(1, 14)),
               "b. Course assignments" = rep(1, 15),
               "c. Collaborative learning experiences (peer review, teamwork, partnered learning, etc.)" = c(rep(0, 8), 1, 1, rep(0, 5)),
               "d. Hands-on experiences (e.g., labs, field trips, field work, community-engaged learning)" = rep(0, 15),
               "e. Clarity in guidelines or requirements for assignments" = c(1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1),
               "f. Explanation of challenging concepts / methods" = c(0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1),
               "g. Inclusion of diverse voices and perspectives in the course materials" = c(rep(0, 10), 1, rep(0, 4)),
               "h. Use of a variety of teaching methods (lecture, group work, problem solving, discussion, etc.)" = c(0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1),
               "i. Instructor’s receptiveness to diverse student viewpoints" = c(rep(0, 14), 1),
               "j. Instructor’s sensitivity to students of different backgrounds and life experiences" = rep(0, 15),
               "k. Instructor’s availability to students during office hours and/or via email" = c(1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0),
               "l. Feedback on graded work" = c(0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1))
toy_df_full <- toy_df_full |> rename(Course_Materials = 'a. Course materials',
                      Course_Assignments = 'b. Course assignments',
                      Collaborative_Learning = 'c. Collaborative learning experiences (peer review, teamwork, partnered learning, etc.)',
                      Hands_on_Experiences = 'd. Hands-on experiences (e.g., labs, field trips, field work, community-engaged learning)',
                      Clarity_of_Assignments = 'e. Clarity in guidelines or requirements for assignments',
                      Explanations_of_Concepts = 'f. Explanation of challenging concepts / methods',
                      Diversity = 'g. Inclusion of diverse voices and perspectives in the course materials',
                      Variety_of_Methods = 'h. Use of a variety of teaching methods (lecture, group work, problem solving, discussion, etc.)',
                      Receptiveness = 'i. Instructor’s receptiveness to diverse student viewpoints',
                      Sensitivity_to_Students = 'j. Instructor’s sensitivity to students of different backgrounds and life experiences',
                      Availability = 'k. Instructor’s availability to students during office hours and/or via email',
                      Feedback = 'l. Feedback on graded work')
toy_df_full <- toy_df_full |> pivot_longer(cols = c(Course_Materials,
                                     Course_Assignments,
                                     Collaborative_Learning,
                                     Hands_on_Experiences,
                                     Clarity_of_Assignments,
                                     Explanations_of_Concepts,
                                     Diversity,
                                     Variety_of_Methods,
                                     Receptiveness,
                                     Sensitivity_to_Students,
                                     Availability,
                                     Feedback),
                       names_to = "check_boxes", values_to = "ind")
toy_df_full$yes_or_no = ifelse(toy_df_full$ind == "1", "Yes", "No") 

toy_df_inorder <- toy_df_full |> group_by(check_boxes, ind) |>
  summarise(total = n()) |>
  arrange(desc(ind), desc(total)) 
toy_df_inorder |> print(n = 12)

toy_df_inorder2 <- toy_df_full |> mutate(check_boxes2 = fct_relevel(check_boxes, c("Course_Assignments",
                                                                "Course_Materials",
                                                                "Availability",
                                                                "Clarity_of_Assignments",
                                                                "Variety_of_Methods",
                                                                "Explanations_of_Concepts",
                                                                "Feedback",
                                                                "Collaborative_Learning",
                                                                "Diversity",
                                                                "Receptiveness",
                                                                "Hands_on_Experiences",
                                                                "Sensitivity_to_Students")))

ggplot(data = toy_df_inorder2, aes(x = student_id, y = fct_rev(check_boxes2))) +
  geom_tile(aes(fill = fct_rev(yes_or_no)), 
            colour = "black") +
  scale_fill_manual(values = c("#FDE725FF", "#440154")) +
  theme_classic(base_size = 14) +
  labs(x = "Student ID",
       y = "Check Boxes",
       fill = "Response",
       title = "Reflect on your learning in this course as a whole.",
       subtitle = "Identify the top 3-5 elements that contributed the most to your learning.") +
  theme(plot.title = element_text(hjust = 0.5,
                                  size = 12),
        plot.subtitle = element_text(hjust = 0.5,
                                     size = 10),
        axis.text.y = element_text(size = 6)) 
```

# Modeling with Ordinal Logistic Regression

-   Fitted ordinal logistic regression model to predict and visualize probability of student responses based on student class year and sex

```{r, echo = FALSE, message = FALSE, warning = FALSE, results = 'hide'}
library(knitr)
library(pander)
library(tidyverse)
library(dplyr)
library(pdftools)
library(MASS)
library(reshape2)
library(kableExtra)
library(gridExtra)
library(ggplot2)
# table
modeling_data_full <- read_csv(here("ordinal_regression/modeling_data_student_by_student.csv"))
modeling_data_full
modeling_data_full <- modeling_data_full |> filter(is.na(Gender) != TRUE) |>
  dplyr::mutate(Year = as.factor(Year)) |>
  dplyr::mutate(Gender = as.factor(Gender)) |> 
  dplyr::mutate(Reason = as.factor(Reason)) |>
  dplyr::mutate(Response = as.factor(Response)) |>
  mutate(reason = fct_recode(Reason, 
                             Major = "1",
                             Minor = "2",
                             Distribution = "3",
                             Interest = "4",
                             Instructor = "5",
                             Other = "6")) |>
  mutate(year = fct_recode(Year,
                           First_Year = "1",
                           Sophomore = "2",
                           Junior = "3",
                           Senior = "4")) |>
  mutate(gender = fct_recode(Gender,
                             Male = "1",
                             Female = "2",
                             Other = "3",
                             PNTD = "4")) |>
  mutate(response = fct_recode(Response,
                               DisagreeStrongly = "1",
                               Disagree = "2",
                               DisagreeSomewhat = "3",
                               Neutral = "4",
                               AgreeSomewhat = "5",
                               Agree = "6",
                               AgreeStrongly = "7")) |>
  dplyr::mutate(new_responses = fct_collapse(response,
                                                  Agree = c("AgreeStrongly",
                                                            "Agree"),
                                                  Neutral = c("AgreeSomewhat",
                                                              "Neutral",
                                                              "DisagreeSomewhat"),
                                                  Disagree = c("Disagree",
                                                               "DisagreeStrongly"))) |>
  dplyr::mutate(year_coll = fct_collapse(year,
                                         Upperclassmen = c("Junior",
                                                           "Senior")))
modeling_data_full 
total_gender <- modeling_data_full |> group_by(gender) |> summarise(total = n())
total_gender
total_year <- modeling_data_full |> group_by(year) |> summarise(total = n())
total_year
df_1 <- modeling_data_full |> group_by(gender, year) |> summarise(total = n()) |>
  filter(is.na(gender) != TRUE) |>
  dplyr::select(-year)
df_1 |> arrange(gender)
# model and viz
mod <- modeling_data_full |> filter(gender != "Other")
mod
olr_mod_2 <- polr(response ~ year_coll + gender, data = mod, Hess = TRUE) 
summary(olr_mod_2)
probs_2 <- cbind(mod, predict(olr_mod_2, type = "probs")) |>
  dplyr::select(-reason, -year, -Year, -Response, -Semester, -Course,
                -response, -new_responses, -Gender)
probs_2 <- probs_2 |> dplyr::rename(Gender = 'gender') |>
  dplyr::rename(Year = 'year_coll') |>
  dplyr::select(-Reason)
head(probs_2)
melt_df_2 <- melt(probs_2, id.vars = c("Gender", "Year"),
                variable.name = "Level", value.name = "Probability")
melt_df_2 <- melt_df_2 |>
  mutate(Level = fct_relevel(Level, c("AgreeStrongly",
                                      "Agree",
                                      "AgreeSomewhat",
                                      "Neutral",
                                      "DisagreeSomewhat"))) 
```

```{r}
tab <- matrix(c(50, 26, 5,
                37, 34, 8, 
                0, 1, 0), ncol = 3)
rownames(tab) <- c('First_Year',
                   'Sophomore',
                   'Upperclassmen')
colnames(tab) <- c('Male',
  'Female',
  'Other')
tab <- as.table(tab)
t <- tab |>
  kable()
t <- t |> kable_styling(full_width = FALSE,
                        position = "center",
                        font_size = 15) |>
  kable_classic()
t
```

```{r, out.width = "800px", fig.align = "center"}
ggplot(melt_df_2, aes(x = Year, y = Probability, colour = Level)) +
  geom_point() +
  geom_line(aes(group = Level)) +
  scale_colour_viridis_d() +
  facet_grid(~Gender, labeller = "label_both") +
  labs(x = "Year",
       caption = "One student identified as Other, responding with Agree") +
  theme_classic(base_size = 14) +
  theme(axis.text.x = element_text(angle = 45, size = 7,
                                   vjust = 1, hjust = 1))
```

-   This model predicts responses for only one professor and course, but could be expanded to quantify systematic biases in student evaluations using other predictors such as professor gender, race and ethnicity, and course type (Diversity, Arts, Humanities, STEM).

# References

<font size = "5">Barry, D. (2017). *bookdown: Do not use averages with Likert scale data.* <https://bookdown.org/Rmadillo/likert/>.</font> <br> <font size = "5">Chávez, Kerry, and Kristina M.W. Mitchell. "Exploring Bias in Student Evaluations: Gender, Race, and Ethnicity.*PS: Political Science & Politics*, vol.53, no.2, 2020, pp.270-274.,<doi:10.1017/S1049096519001744></font> <br> <font size = "5">Joshi, A., Kale, S., Chandel, S., & Pal, D. K. (2015). Likert Scale: Explored and Explained. *British Journal of Applied Science and Technology, 7*(4), 396-403.</font>
